{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.load_data import load_train, load_test, load_example\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image recognition met een \"normaal\" neuraal netwerk. \n",
    "\n",
    "Neurale netwerken zijn ontzettend sterke wiskundige modellen. Een “normaal” neuraal netwerk heeft echter wel wat limieten. Om een aantal van deze limieten te doorbreken, kan je een convolutional neuraal netwerk gebruiken. \n",
    "\n",
    "We beginnen met het exploreren van de limieten van normale neurale netwerken, dit doen we doormiddel van de MNIST-dataset.\n",
    "\n",
    "MNIST is een dataset van 70.000 handgeschreven cijfers (0..9), opgesplitst in 60.000 training images en 10.000 testing images. We hebben al functies geschreven waarmee je de data kan inladen, zie de cell hieronder.\n",
    "\n",
    "Deze data is steeds opgedeeld in 2 stukken: train en labels.\n",
    "\n",
    "train is een (numpy) array met alle inputafbeeldingen erin.\n",
    "labels is een (numpy) array met voor elke inputafbeelding de werkelijke waarde.\n",
    "\n",
    "Als train[5] een afbeelding van een 4 is, dan geldt dus: labels[5] == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 31)\n",
      "Label: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Laad de trainingsdata en labels\n",
    "train_data, train_labels = load_train()\n",
    "# De kleurwaarden in de afbeelding zijn nu 0 tot 255, we zetten deze om naar -0.5 tot 0.5\n",
    "train_data = (train_data / 255) - 0.5\n",
    "\n",
    "print(train_data.shape)\n",
    "\n",
    "plt.imshow(train_data[3])\n",
    "plt.title(f\"{train_labels[3]}\")\n",
    "print(f\"Label: {train_labels[3]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data formatting\n",
    "Voordat we een neuraal netwerk kunnen trainen op de MNIST-data, moet deze verwerkt worden.\n",
    "\n",
    "De input data zijn op het moment grijsafbeeldingen, en dus 2-dimensionaal (x,y).\n",
    "Alleen elke input van dit neuraal netwerk moet 1-dimensionaal zijn. Probeer nu zelf train_data om te zetten naar een\n",
    "correct format. De labels hebben wij zelf al voor je omgezet naar het juiste formaat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 868)\n"
     ]
    }
   ],
   "source": [
    "train_labels = load_train()\n",
    "train_data = train_data.reshape(train_data.shape[0], (train_data.shape[1] * train_data.shape[2]))\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 868)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handig om te weten: Image recognition geeft in het algemeen ontzettend grote input vectors.\n",
    "MNIST is in grayscale, maar veel plaatjes zijn dat niet. Als je ook nog kleur wil meegeven,\n",
    "zou de input vector nog drie keer zo groot zijn.\n",
    "\n",
    "### Bouwen van een NN\n",
    "\n",
    "De volgende stap is om een neuraal netwerk te bouwen.\n",
    "Maak zelf de eerste Dense layer af, kijk vervolgens ook naar hoeveel hidden layers je toevoegt.\n",
    "Bij image recognition is de activation function ook erg belangrijk.\n",
    "Denk goed na over welke je gebruikt. De laatste layer geven wij alvast aan je.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 32)                27808     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,138\n",
      "Trainable params: 28,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# input_dim moet gelijk zijn aan de lengte van 1 input\n",
    "model.add(Dense(32, input_dim= train_data.shape[1]))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieruit kan je al direct het eerste probleem van normale neurale netwerken inzien; er is een gigantische hoeveelheid trainbare parameters. \n",
    "\n",
    "Iedere node moet verbonden zijn aan iedere node. Bij image recognition is de input vector gigantisch, dit houdt dus ook in dat er een gigantische hoeveelheid weights zijn waarmee jouw neuraal netwerk rekening moet houden. \n",
    "\n",
    "Dit maakt het trainen best zwaar en langzaam.\n",
    "\n",
    "Het klaarmaken van een neural network in Keras heeft de volgende stappen:\n",
    "- Aangeven van de layers, dit hebben we net gedaan\n",
    "- Compilen, het model word nu geconfigureerd om hem klaar te maken voor trainen\n",
    "- Fit, het model word nu \"getraind\" op data die je meegeeft. Hieraan geef je zowel data als labels mee\n",
    "- Evaluate; Controller het model om te kijken of het accuraat is. Geef hieraan data en labels mee, maar zorg dat deze data niet ook in je trainingsdata zit\n",
    "- Predict; Geef inputdata mee, waarvan je het label nog niet kent. het NN probeert het label nu te bedenken.\n",
    "Ga nu door met het trainen van dit neuraal netwerk. Ook de `.compile()` hebben wij al aan je geven, ook hier mag je mee spelen.\n",
    "\n",
    "Probeer jouw neuraal netwerk zo accuraat mogelijk te maken. (doe dit door te kijken naar de resultaten van de `.fit()`; `.evaluate()` komt later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In AI is het aantal epochs het aantal keer dat je over de volledige dataset heen gaat om te trainen.\n",
    "\n",
    "Experimenteer met deze waarde om te kijken wat voor invloed deze heeft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 868)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\coenc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\coenc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\coenc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\coenc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\coenc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\coenc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\coenc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\coenc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\coenc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\coenc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 28, 31) and (32, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_labels[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\coenc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\coenc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\coenc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\coenc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\coenc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\coenc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\coenc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\coenc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\coenc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\coenc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 28, 31) and (32, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_labels[0][0][0])\n",
    "\n",
    "model.fit(train_data, train_labels, epochs=50) # FIXME set epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Het evalueren van het neurale netwerk\n",
    "Ook hier moet de data eerst nog omgevormd worden, gebruik hiervoor dezelfde code als bij de training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_labels = load_test()\n",
    "\n",
    "test_data = test_data/255.0 - 0.5\n",
    "\n",
    "\n",
    "test_data =  # FIXME\n",
    "test_labels = to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(test_data, test_labels)\n",
    "\n",
    "print(f\"loss: {result[0]}, accuracy: {result[1]} van de 1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huh?\n",
    "Hoogstwaarschijnlijk scoort jouw neuraal netwerk nu ontzettend slecht. Om een limiet van neurale netwerken zichtbaar te maken, hebben we een klein beetje valsgespeeld. We hebben wat padding toegevoegd; een aantal pixels aan de linkerkant bij de testing data en een aantal pixels aan de rechterkant bij de training data. Zie de plots hieronder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(example_r, example_l), label = load_example()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].imshow(example_r)\n",
    "axs[0].set_title(\"Padding on right side (Like training)\")\n",
    "\n",
    "axs[1].imshow(example_l)\n",
    "axs[1].set_title(\"Padding on left side (Like testing)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De standaardwaarde voor de padding is 3(!!) pixels, dit heeft een gigantisch effect op de accuratesse.\n",
    "Formatteer nog één keer de data (`examples`), en kijk wat er uit de `.predict()` komt.\n",
    "\n",
    "Er bestaat een kans dat jouw model hier de goede voorspelt, probeer dan bij `load_example()` het argument `index` te veranderen naar een ander getal. Waarschijnlijk zal het dan wel fout voorspellen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = np.array([example_r, example_l]) # FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waarom?\n",
    "\n",
    "De voorspellingen van een gewoon neuraal netwerk zijn ruimtelijk bepaald, het herkent patronen op specifieke plekken. Het verplaatsen van deze patronen met maar een paar pixels kan al genoeg zijn om het onmogelijk te maken voor een gewoon neuraal netwerk om deze te herkennen. \n",
    "\n",
    "Een neuraal netwerk getraind op het herkennen van honden en fietsen, zou heel makkelijk het volgende gedrag kunnen laten zien:\n",
    "\n",
    "\n",
    "\n",
    "![Right!](src/top-left-dog.png)\n",
    "\n",
    "![Wrong!](src/top-left-bike.png)\n",
    "\n",
    "\n",
    "Speel is een beetje rond met de padding, kijk is hoeveel impact 4 pixels heeft, zelfs 1 pixel kan al een grote impact hebben!\n",
    "\n",
    "Wij raden aan om alleen de horizontale padding te veranderen, het format van het padding argument in `load_train`, `load_test`, en `load_example` is dan: `((0, 0), (0, 0), (left sided padding, right sided padding))`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aldewereld, H. & van der Bijl, B. & Bunk, J. (2017, oktober). Applied Artificial Intelligence. Geraadpleegd op 13 maart 2020, van https://canvas.hu.nl/courses/7569/files/694738/download?wrap=1\n",
    "\n",
    "- Chollet, F. (2019, November 6). Getting started with the Keras Sequential model. Geraadpleegd op 13 maart 2020, van keras.io: https://keras.io/getting-started/sequential-model-guide/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
